# trabalho_cogumelo2
# Resultados Treinamentos

## Requisitos

- Python 3.11.6
- pips:
﻿annotated-types==0.7.0 <br>
asttokens==3.0.0 <br>
attrs==25.3.0 <br>
beautifulsoup4==4.13.3 <br>
bleach==6.2.0 <br>
blinker==1.9.0 <br>
Brotli==1.1.0 <br>
category_encoders==2.7.0 <br>
certifi==2025.1.31 <br>
charset-normalizer==3.4.1 <br>
click==8.1.8 <br>
cloudpickle==3.1.1 <br>
colorama==0.4.6 <br>
comm==0.2.2 <br>
contourpy==1.3.1 <br>
cycler==0.12.1 <br>
Cython==3.0.12 <br>
dacite==1.9.2 <br>
dash==2.18.2 <br>
dash-bootstrap-components==1.7.1 <br>
dash-core-components==2.0.0 <br>
dash-html-components==2.0.0 <br>
dash-table==5.0.0 <br>
dash_daq==0.5.0 <br>
decorator==5.2.1 <br>
deprecation==2.1.0 <br>
dtale==3.17.0 <br>
et_xmlfile==2.0.0 <br>
executing==2.2.0 <br>
fastjsonschema==2.21.1 <br>
Flask==3.0.3 <br>
Flask-Compress==1.17 <br>
fonttools==4.57.0 <br>
future==1.0.0 <br>
htmlmin==0.1.12 <br>
idna==3.10 <br>
ImageHash==4.3.1 <br>
imbalanced-learn==0.13.0 <br>
importlib_metadata==8.6.1 <br>
ipython==9.0.2 <br>
ipython_pygments_lexers==1.1.1 <br>
ipywidgets==8.1.5 <br>
itsdangerous==2.2.0 <br>
jedi==0.19.2 <br>
Jinja2==3.1.6 <br>
joblib==1.3.2 <br>
jsonschema==4.23.0 <br>
jsonschema-specifications==2024.10.1 <br>
jupyter_core==5.7.2 <br>
jupyterlab_widgets==3.0.13 <br>
kaggle==1.7.4.2 <br>
kaleido==0.2.1 <br>
kiwisolver==1.4.8 <br>
lightgbm==4.6.0 <br>
llvmlite==0.44.0 <br>
lz4==4.4.4 <br>
MarkupSafe==3.0.2 <br>
matplotlib==3.7.5 <br>
matplotlib-inline==0.1.7 <br>
missingno==0.5.2 <br>
multimethod==1.12 <br>
narwhals==1.33.0 <br>
nbformat==5.10.4 <br>
nest-asyncio==1.6.0 <br>
networkx==3.4.2 <br>
numba==0.61.0 <br>
numpy==1.26.4 <br>
openpyxl==3.1.5 <br>
orjson==3.10.16 <br>
packaging==24.2 <br>
pandas==2.1.4 <br>
parso==0.8.4 <br>
patsy==1.0.1 <br>
phik==0.12.4 <br>
pillow==11.1.0 <br>
platformdirs==4.3.7 <br>
plotly==5.24.1 <br>
plotly-resampler==0.10.0 <br>
pmdarima==2.0.4 <br>
prompt_toolkit==3.0.50 <br>
protobuf==6.30.2 <br>
psutil==7.0.0 <br>
pure_eval==0.2.3 <br>
puremagic==1.28 <br>
pycaret==3.3.2 <br>
pydantic==2.11.2 <br>
pydantic_core==2.33.1 <br>
Pygments==2.19.1 <br>
pynndescent==0.5.13 <br>
pyod==2.0.4 <br>
pyparsing==3.2.3 <br>
python-dateutil==2.9.0.post0 <br>
python-slugify==8.0.4 <br>
pytz==2025.2 <br>
PyWavelets==1.8.0 <br>
pywin32==310 <br>
PyYAML==6.0.2 <br>
referencing==0.36.2 <br>
requests==2.32.3 <br>
retrying==1.3.4 <br>
rpds-py==0.24.0 <br>
schemdraw==0.15 <br>
scikit-base==0.7.8 <br>
scikit-learn==1.4.2 <br>
scikit-plot==0.3.7 <br>
scipy==1.11.4 <br>
seaborn==0.13.2 <br>
shap==0.47.2 <br>
six==1.17.0 <br>
sklearn-compat==0.1.3 <br>
sktime==0.26.0 <br>
slicer==0.0.8 <br>
soupsieve==2.6 <br>
squarify==0.4.4 <br>
stack-data==0.6.3 <br>
statsmodels==0.14.4 <br>
strsimpy==0.2.1 <br>
tbats==1.1.3 <br>
tenacity==9.1.2 <br>
text-unidecode==1.3 <br>
threadpoolctl==3.6.0 <br>
tqdm==4.67.1 <br>
traitlets==5.14.3 <br>
tsdownsample==0.1.4.1 <br>
typeguard==4.4.2 <br>
typing-inspection==0.4.0 <br>
typing_extensions==4.13.1 <br>
tzdata==2025.2 <br>
umap==0.1.1 <br>
umap-learn==0.5.7 <br>
urllib3==2.3.0 <br>
visions==0.8.1 <br>
wcwidth==0.2.13 <br>
webencodings==0.5.1 <br>
Werkzeug==3.0.6 <br>
widgetsnbextension==4.0.13 <br>
wordcloud==1.9.4 <br>
xarray==2025.3.1 <br>
xlrd==2.0.1 <br>
xxhash==3.5.0 <br>
ydata-profiling==4.16.1 <br>
yellowbrick==1.5 <br> 
zipp==3.21.0 <br>
zstandard==0.23.0 <br>

## Como instalar

Você pode instalar todas as dependências de uma vez usando o comando:

```bash```
pip install -r requirements.txt

## Como rodar

# Criar ambiente virtual
python -m venv venv
.\venv\Scripts\activate

# Instalar dependências
pip install -r requirements.txt

# Rodar o pipeline
python main.py train
python main.py visualize --clean-data data/mushrooms_edited.csv

Model  Accuracy     AUC  Recall   Prec.  \ <br>
knn                K Neighbors Classifier    1.0000  1.0000  1.0000  1.0000 <br>
svm                   SVM - Linear Kernel    1.0000  1.0000  1.0000  1.0000 <br>
rf               Random Forest Classifier    1.0000  1.0000  1.0000  1.0000 <br>
qda       Quadratic Discriminant Analysis    1.0000  1.0000  1.0000  1.0000 <br>
et                 Extra Trees Classifier    1.0000  1.0000  1.0000  1.0000 <br>
lightgbm  Light Gradient Boosting Machine    1.0000  1.0000  1.0000  1.0000 <br>
lr                    Logistic Regression    0.9998  1.0000  0.9998  0.9998 <br>
dt               Decision Tree Classifier    0.9998  0.9998  0.9998  0.9998 <br>
ada                  Ada Boost Classifier    0.9998  1.0000  0.9998  0.9998 <br>
ridge                    Ridge Classifier    0.9996  1.0000  0.9996  0.9996 <br>
gbc          Gradient Boosting Classifier    0.9996  1.0000  0.9996  0.9996 <br>
lda          Linear Discriminant Analysis    0.9996  0.9993  0.9996  0.9996 <br>
nb                            Naive Bayes    0.9639  0.9968  0.9639  0.9666 <br>
dummy                    Dummy Classifier    0.5179  0.5000  0.5179  0.2683 <br>

              F1   Kappa     MCC  TT (Sec) <br>
knn       1.0000  1.0000  1.0000     0.535 <br>
svm       1.0000  1.0000  1.0000     0.162 <br>
rf        1.0000  1.0000  1.0000     0.224 <br>
qda       1.0000  1.0000  1.0000     0.193 <br>
et        1.0000  1.0000  1.0000     0.200 <br>
lightgbm  1.0000  1.0000  1.0000     0.287 <br>
lr        0.9998  0.9996  0.9996     0.800 <br>
dt        0.9998  0.9996  0.9996     0.171 <br>
ada       0.9998  0.9996  0.9996     0.311 <br>
ridge     0.9996  0.9993  0.9993     0.166 <br>
gbc       0.9996  0.9993  0.9993     0.294 <br>
lda       0.9996  0.9993  0.9993     0.191 <br>
nb        0.9639  0.9280  0.9305     0.176 <br>
dummy     0.3535  0.0000  0.0000     0.168 <br>
Best Classification Model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', <br>
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2, <br>
                     weights='uniform') <br>
Training complete. Model object: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', <br>
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2, <br>
                     weights='uniform') <br>

------------------------------------------------------------

2025-04-13 19:58:53,982 [INFO] Training a model on mushrooms.csv | Target: class | Task: classification <br>
                    Description             Value <br>
0                    Session id               123 <br>
1                        Target             class <br>
2                   Target type            Binary <br>
3                Target mapping        e: 0, p: 1 <br>
4           Original data shape        (8124, 23) <br>
5        Transformed data shape       (8124, 113) <br>
6   Transformed train set shape       (5686, 113) <br>
7    Transformed test set shape       (2438, 113) <br>
8          Categorical features                22 <br>
9                    Preprocess              True <br>
10              Imputation type            simple <br>
11           Numeric imputation              mean <br>
12       Categorical imputation              mode <br>
13     Maximum one-hot encoding                25 <br>
14              Encoding method              None <br>
15               Fold Generator   StratifiedKFold <br>
16                  Fold Number                10 <br>
17                     CPU Jobs                -1 <br>
18                      Use GPU             False <br>
19               Log Experiment             False <br>
20              Experiment Name  clf-default-name <br>
21                          USI              f91d <br>
